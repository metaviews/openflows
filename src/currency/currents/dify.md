---
layout: layouts/currency-item.njk
title: "Dify"
date: 2026-02-25
currencyType: "current"
currencyId: dify
abstract: "An open-source LLM application platform for building and operating AI workflows with visible orchestration layers."
tags:
  - currency
permalink: /currency/currents/dify/
links:
  - id: local-inference-baseline
    relation: "extends practical app-layer operations on top of"
---

### Signal

[Dify](https://github.com/langgenius/dify) packages application-building primitives for LLM products into an open-source, self-hostable platform.

### Context

The movement here is from isolated prompt experiments to managed AI applications with explicit workflow components, model connections, and operational controls.

### Relevance

For Openflows, this supports inspectable service assembly. Teams can expose and tune mediation layers instead of treating application behavior as a closed black box.

### Current State

Strong platform signal in open LLM app operations.

### Open Questions

- Which governance controls are essential before multi-user deployment?
- How portable are workflows across model providers and hosting modes?
- What observability baseline is needed to audit production behavior over time?

### Connections

- Linked to `local-inference-baseline` as the enabling infrastructure layer.
