---
layout: layouts/currency-item.njk
title: "LM Studio"
date: 2026-02-11
currencyType: "current"
currencyId: lm-studio
abstract: "A desktop application that makes local language model inference accessible and ordinary."
tags:
  - currency
links:
  - id: local-inference-baseline
    relation: "consolidates into"
---

### Signal

[LM Studio](https://lmstudio.ai/) makes local language model inference directly accessible through a desktop interface for model management and interaction.

### Context

By reducing environment setup overhead, it turns local model execution into a routine workflow. Models become local assets governed by available hardware constraints.

### Relevance

For Openflows, this supports infrastructural agency. When local inference becomes ordinary, interpretive and operational control becomes materially feasible.

### Current State

Mature and widely legible local inference entry point.

### Open Questions

- Which local workflows remain dependent on cloud integration?
- How can model selection literacy keep pace with expanding options?
- What practices best preserve inspectability as convenience features grow?

### Connections

- Linked to `local-inference-baseline` as a precursor signal.
